# `src` 目录结构说明

本目录包含了项目的所有核心源代码，按照功能进行模块化组织。
## 四大函数
1. 写入 (Write): writehdf5.py 成功将HDF5文件的元数据解析并存入PostgreSQL数据库。
2. 读取 (Read/Extract): extract_hdf5.py 能够根据数据库中的元数据，从原始文件中提取出指定的子集。
3. 插值 (Interpolate): main-new.py 能够将离散的气象数据点，通过插值算法转换成规则的网格数据。
4. 裁剪 (Cropping):从一个大的HDF5文件中，根据您指定的经纬度范围，精确地“裁剪”出一个地理上的子区域，并生成一个新的、更小的HDF5文件
# 文件说明

- `__init__.py`

  - **功能**：一个空文件，用于将 `src` 目录标识为一个Python包。这使得我们可以从项目的其他地方（例如未来的Web应用或测试）导入 `src` 目录下的模块。
- `api_service.py`

  - **功能**：这是项目的**核心业务逻辑层**。它封装了从接收用户请求到完成处理的整个工作流程。它调用其他模块（如数据库查询和裁剪工具）来响应外部请求（例如来自Web API的请求）。
  - **核心函数**：`find_and_crop_hdf5()`

# 目录说明

## `cropper/`

- **功能**：存放所有与**空间裁剪**相关的代码。
- **核心脚本**：`SpaceCropping.py`，定义了 `HDF5Cropper` 类，是执行实际裁剪操作的工具。
-

## `io_lib/`

- **功能**：提供基础的输入/输出（I/O）操作的库或辅助函数，可能被其他模块用于读写文件。

## `__pycache__/`

- **功能**：Python自动生成的目录，用于存放已编译的 `.pyc` 文件，以加快模块加载速度。这个目录不需要手动管理。

## `interpolation/ main-new `

- **功能**： 存放与**插值算法**相关的代码。
  主要功能和特点如下：

1. 数据输入:

   * 接收一个HDF5文件作为输入 (--input-file)。
   * 需要指定文件中一个具体的变量名 (--var-name) 来进行处理，例如 airTemperature (气温) 或
     pressure (气压)。
2. 空间范围裁剪:

   * 用户可以通过参数 (--lon-min, --lon-max, --lat-min, --lat-max)
     指定一个经纬度矩形范围。
   * 脚本只会处理这个指定区域内的数据，非常适合用于区域性研究。
3. 支持三维数据和分层处理:

   * 脚本不仅能处理二维平面数据，还能处理带有垂直分层的三维数据（例如不同高度的气象数据）
     。
   * 用户可以通过 (--layer-min, --layer-max)
     参数选择处理特定的垂直层，例如只处理地面到5000米高空的数据。
4. 数据预处理:

   * 在插值之前，脚本会自动处理原始数据中的缺失值
     (-9999.9)，使用IDW算法进行填充，以保证数据完整性。
5. 高性能并行计算:

   * 脚本使用了 joblib 库进行并行计算 (PARALLEL = True)，能充分利用多核CPU的性能，将大范围
     的插值任务分割成小块（Block）并行处理，大大缩短了计算时间。
6. 结果输出:

   * 处理完成后，会生成一个新的HDF5文件，文件名包含了原始文件名、变量名和 _processed
     后缀。
   * 输出的文件中包含了插值后的规则网格数据（经度、纬度、变量值）。
   * 最后还会生成一份处理报告，总结本次插值的覆盖率、耗时等信息。

  总结来说，这个脚本是一个专业的数据处理工具，主要用于：

> 将原始的、离散分布的气象观测数据，通过插值和裁剪，转换成格式统一、便于后续分析和可视化的规
> 则网格数据。它对于气象建模、数据分析等工作非常有用。

### 命令

   一个典型的运行命令如下所示：

  python3 src/interpolation/main-new.py
 --input-file
 /Users/crocotear/Documents/挑战者杯/data/hdf5/2A.GPM.Ku.V9-20211125.20230101-S23
  1026-E004258.050253.V07A.HDF5
    --var-name airTemperature
     --lon-min 110 --lon-max 120
      --lat-min 30 --lat-max 40
     --output-dir ./out

  这个命令的意思是：

* --input-file: 指定要处理的HDF5文件。
* --var-name: 指定要对 airTemperature 这个变量进行插值。
* --lon-min, --lon-max: 将数据裁剪到东经110度至120度之间。
* --lat-min, --lat-max: 将数据裁剪到北纬30度至40度之间。
* --output-dir: 将处理结果保存到项目根目录下的 out 文件夹中。

  您可以根据自己的需求修改这些参数。如果您不提供经纬度范围，脚本会处理文件中的全部数据。

  * 中国区域: --lon-min 73 --lon-max 135 --lat-min 18 --lat-max 54
  * 北美区域: --lon-min -125 --lon-max -66 --lat-min 25 --lat-max 50

### 信息查询模式

成功地为 main-new.py 添加了 --info 功能。

  现在您可以这样使用它：

1. 快速查询文件信息

  当您想知道一个HDF5文件的数据范围时，可以运行以下命令：

   1 python3 src/interpolation/main-new.py --input-file <你的文件路径> --var-name <变量名> --info

  它会立刻打印出类似下面的信息，然后退出，不会进行

## `others/`

- **功能**： 存放一些未分类的、或辅助性的脚本以及早期测试。

### data_ingestion/

- `hdf5_parser.py`
- `grib_parser.py`

## `read/`

- **功能**：基于扩展的元数据的网格场读取

## `write/`

- **功能**：将原始文件的自描述信息提取并入库，四个层次
