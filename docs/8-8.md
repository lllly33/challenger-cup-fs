## 元数据提取
1. 文件级别元数据 (存入 hdf5_files 表)

  这是最顶层的信息，用于标识和定位文件本身。

* file_name: 文件的基本名称 (例如: 2A.GPM.Ku...V07A.HDF5)。
* file_path: 文件在JuiceFS中的完整存储路径 (例如: /mnt/myjfs/2A.GPM.Ku...V07A.HDF5)。

2. 层级结构元数据 (存入 hdf5_groups 表)

  您完整地保留了HDF5文件的核心层级（目录）结构。

* name: Group（组）的名称。
* full_path: Group在HDF5文件内部的完整路径 (例如: /FS 或 /FS/Swath)。
* parent_path: 父Group的路径，用于维系层级关系。

3. 数据集核心元数据 (存入 hdf5_datasets 表)

  这是最关键的部分之一。您提取了描述数据集（可以理解为数据本身）物理和存储特性的核心信息。

* name: Dataset（数据集）的名称 (例如: Latitude, airTemperature)。
* full_path: Dataset在文件内的完整路径。
* parent_path: 所属Group的路径。
* shape: 数据维度。例如 (1736, 24)，这对于理解数据是几维数组至关重要。
* dtype: 数据类型。例如 float32, int16，这对于正确解析数据至关重要。
* chunks: 分块存储信息。这是HDF5性能优化的关键特性，您也捕捉到了。
* compression: 压缩算法。例如 gzip，表明数据是否被压缩。
* compression_opts: 压缩级别。
* fill_value: 填充值。在科学计算中，识别并忽略无效数据（例如云、陆地等无观测值的区域）的
  填充值是极其重要的步骤。

4. 属性元数据 (存入 hdf5_attributes 表)

  这是您工作中最亮眼、最深入的部分。HDF5的“自描述”特性，其精髓就体现在属性（Attributes）上
  。属性是以键值对形式附加在Group和Dataset上的信息，用于解释它们是什么、单位是什么、如何使
  用等。您对这部分的处理非常细致：

* parent_path: 记录了该属性是附属于哪个Group或Dataset。
* name: 属性的名称（Key），例如 Units, _FillValue, DimensionNames。
* value: 属性的值（Value），例如 m/s, -9999.9, Scan, Swath。您还编写了复杂的逻辑来处理不
  同的值类型（字符串、字节、Numpy数组等），确保信息不丢失。
* 关于属性本身的元数据:
  * is_array: 判断属性值本身是不是一个数组。
  * array_length: 如果是数组，其长度是多少。
  * dtype: 属性值的数据类型。
  * str_length, padding, cset:
    针对字符串类型的属性，甚至还保存了其长度、编码和填充方式等底层信息。


已完成内容总结

  经过我们一系列的调试、重构和功能增强，您的“地球科学数据处理平台”现在已经是一个功能强大、
  逻辑严谨且具备很高完成度的原型系统。

  核心功能与特性：

   1. HDF5文件上传与深度元数据解析:
       * 实现了文件上传功能，并将上传的文件存储在JuiceFS中。
       * 构建了最核心的 writehdf5.py
         模块，它能对HDF5文件进行深度扫描，将其内部的文件、组、数据集、属性等全部自描述信息
         ，完整、结构化地存入PostgreSQL数据库。这是整个系统高效运行的基石。

   2. 异步任务处理架构:
       * 采用Flask + multiprocessing 构建了后台工作进程（Worker）模型。
       * 对于裁剪、插值等耗时操作，实现了“提交任务 -> 立即返回 -> 后台处理 -> 状态轮询 ->
         下载结果”的完整异步流程，保证了前端界面的流畅响应。

   3. 健壮且通用的数据处理API:
       * 空间裁剪 (`/api/crop`):
         能够根据用户指定的经纬度范围，自动在文件中查找经纬度变量并执行裁剪。
       * 空间插值 (`/api/interpolate`): 经过重构，现在的插值功能非常强大：
           * 路径动态发现: 不再依赖硬编码的路径，而是通过查询数据库，动态获取变量和经纬度在
             文件中的确切位置。
           * 环境路径自适应: 能够自动处理开发环境 (/mnt/myjfs) 和生产环境 (/mnt/jfs)
             之间挂载点路径的差异。
           * 支持多种数据结构: 能够正确处理二维网格和一维坐标轴两种形式的经纬度数据。

   4. 专业的用户交互界面:
       * 实现了基于文件、组、变量的“三级联动选择”功能，让用户可以像使用专业软件一样，先选择
         数据组，再选择该组内的变量，极大地提升了操作的准确性和用户体验。
       * 前端能够动态加载参数、轮询任务状态并提供下载链接，交互逻辑完整。

  系统解决了的关键问题：

   * 数据发现: 将黑盒的HDF5文件透明化，所有内部结构都可被查询。
   * 性能瓶颈: 通过元数据索引，避免了对大文件的全盘扫描，为高效访问打下基础。
   * 环境差异: 解决了开发环境和生产环境配置不同导致的路径问题。
   * 数据适用性:
     解决了因数据类型或维度不匹配导致程序崩溃的问题，并从交互层面引导用户做出正确的选择。

  一句话总结：我们已经构建了一个从数据入口、元数据管理、核心算法处理到前端交互都非常完善的
  科学数据处理原型系统，它不仅能跑通，而且跑得聪明、跑得健壮。

  ---

  服务器部署修改指南

  当您准备将此项目部署到生产服务器（例如
  node1）时，主要需要关注的是环境配置的差异。修改工作非常少，主要集中在以下几个文件：

   1. `src/api_service.py`:
       * 需要修改的地方: 文件顶部的路径转换配置。
       * 如何修改:

   1         # --- 路径转换配置 (用于适配开发环境和生产环境) ---
   2         # 数据库中存储的生产环境路径前缀
   3         DB_PATH_PREFIX = '/mnt/jfs/'
   4         # 部署到服务器时，本地挂载点和数据库路径前缀是相同的
   5         LOCAL_MOUNT_POINT = '/mnt/jfs/' # <--- 将 /mnt/myjfs/ 修改为 /mnt/jfs/

   2. `src/interpolation/main_new.py`:
       * 需要修改的地方: 文件顶部的路径转换配置。
       * 如何修改:

   1         # ...
   2         DB_PATH_PREFIX = '/mnt/jfs/'
   3         LOCAL_MOUNT_POINT = '/mnt/jfs/' # <--- 将 /mnt/myjfs/ 修改为 /mnt/jfs/

   3. `app.py`:
       * 需要修改的地方: JUICEFS_MOUNT_POINT
         常量。这个常量主要在文件上传时使用，用来构建文件在JuiceFS中的目标路径。
       * 如何修改:
   1         # ...
   2         JUICEFS_MOUNT_POINT = '/mnt/jfs/'  # <--- 将 /mnt/myjfs/ 修改为
     /mnt/jfs/

   4. 数据库连接参数 (如果需要):
       * 涉及文件: src/write/writehdf5.py, src/api_service.py,
         src/interpolation/main_new.py。
       * 检查点: 目前所有文件中的 DB_HOST 都硬编码为 "localhost"。如果您的PostgreSQL数据库和
         Web应用部署在同一台服务器上，这没有问题。如果它们位于不同的服务器，您需要将
         localhost 修改为PostgreSQL服务器的IP地址或主机名。

  部署清单总结：


  ┌────────────────────────────┬────────────────┬───────────────┬──────────────────┐
  │ 文件路径                   │ 需要修改的...  │ 从... (开...  │ 修改为... (生... │
  ├────────────────────────────┼────────────────┼───────────────┼──────────────────┤
  │ src/api_service.py         │ `LOCAL_MOUN... │ '/mnt/myjfs/' │ '/mnt/jfs/'      │
  │ `src/interpolation/main... │ `LOCAL_MOUN... │ '/mnt/myjfs/' │ '/mnt/jfs/'      │
  │ app.py                     │ `JUICEFS_MO... │ '/mnt/myjfs/' │ '/mnt/jfs/'      │
  │ (可能) `.../api_service... │ DB_HOST        │ 'localhost'   │ 数据库服务器I... │
  └────────────────────────────┴────────────────┴───────────────┴──────────────────┘


  就是这样。整个项目的代码耦合度很低，环境相关的配置都集中在几个文件的顶部，所以部署工作会
  非常轻松。


  核心原则：
  在本地开发时，我们使用了 /mnt/myjfs/
  作为JuiceFS的挂载点，而在您的服务器上，JuiceFS的挂载点是
  /mnt/jfs/。数据库中存储的文件路径也是 /mnt/jfs/。为了让代码在服务器上直接使用这些路径，
  我们需要将代码中所有指向本地开发环境挂载点的配置，修改为服务器上的实际挂载点。

  ---

  1. app.py

   * 目的: 这个文件主要在文件上传时，构建文件在JuiceFS中的目标路径。
   * 需要修改的变量: JUICEFS_MOUNT_POINT
   * 修改方式:

   1     # app.py
   2     # ...
   3     JUICEFS_MOUNT_POINT = '/mnt/jfs'  # <--- 将 '/mnt/myjfs' 修改为 '/mnt/jfs'
   4     # ...

  ---

  2. src/api_service.py

   * 目的: 这个文件负责与数据库交互，并执行裁剪和插值操作。它需要知道JuiceFS的实际挂载点，以
     便正确地访问HDF5文件。
   * 需要修改的变量: LOCAL_MOUNT_POINT 和 DB_HOST
   * 修改方式:

    1     # src/api_service.py
    2     # ...
    3     # --- 数据库连接参数 (与 writehdf5.py 保持一致) ---
    4     DB_HOST = "localhost" # <---
      如果数据库不在同一台服务器，需要修改为数据库的IP或主机名
    5     DB_NAME = "juicefs"
    6     DB_USER = "juiceuser"
    7     DB_PASSWORD = "0333"
    8
    9     # --- 路径转换配置 (用于适配开发环境和生产环境) ---
   10     # 数据库中存储的生产环境路径前缀
   11     DB_PATH_PREFIX = '/mnt/jfs/'
   12     # 部署到服务器时，本地挂载点和数据库路径前缀是相同的
   13     LOCAL_MOUNT_POINT = '/mnt/jfs/' # <--- 将 '/mnt/myjfs/' 修改为 '/mnt/jfs/'
   14     # ...

  ---

  3. src/interpolation/main_new.py

   * 目的: 这个文件是插值算法的核心，它也需要知道JuiceFS的实际挂载点来读取HDF5文件。
   * 需要修改的变量: LOCAL_MOUNT_POINT 和 DB_HOST
   * 修改方式:

    1     # src/interpolation/main_new.py
    2     # ...
    3     # --- 数据库连接参数 ---
    4     DB_HOST = "localhost" # <---
      如果数据库不在同一台服务器，需要修改为数据库的IP或主机名
    5     DB_NAME = "juicefs"
    6     DB_USER = "juiceuser"
    7     DB_PASSWORD = "0333"
    8
    9     # ...
   10     DB_PATH_PREFIX = '/mnt/jfs/'
   11     LOCAL_MOUNT_POINT = '/mnt/jfs/' # <--- 将 '/mnt/myjfs/' 修改为 '/mnt/jfs/'
   12     # ...

  ---

  4. src/write/writehdf5.py

   * 目的: 这个文件负责将HDF5文件的元数据写入数据库。它也需要知道JuiceFS的实际挂载点，以便将
     正确的文件路径记录到数据库中。
   * 需要修改的变量: DB_HOST
   * 修改方式:

   1     # src/write/writehdf5.py
   2     # ...
   3     # PostgreSQL 数据库连接参数
   4     DB_HOST = "localhost" # <---
     如果数据库不在同一台服务器，需要修改为数据库的IP或主机名
   5     DB_NAME = "juicefs"
   6     DB_USER = "juiceuser"
   7     DB_PASSWORD = "0333"
   8     # ...
